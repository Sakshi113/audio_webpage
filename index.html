<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Towards Open & Accessible Audio General Intelligence for All</title>
    <link rel="stylesheet" href="style.css">
    <link rel="icon" href="favicon.ico" type="image/x-icon">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>
<body>

    <header>
        <div class="header-container">
            <img src="assets/umd.png" alt="UMD Logo" class="logo-left">
            <h1>Towards Open & Accessible Audio General Intelligence for All</h1>
            <img src="assets/gamma_logo-2.png" alt="GAMMA Lab Logo" class="logo-right">
        </div>
    </header>

    <!-- Navigation Bar -->
    <nav class="navbar">
        <ul>
            <li><a href="index.html"><i class="fas fa-home"></i> Home</a></li>
            <li><a href="research.html"><i class="fas fa-flask"></i> Research</a></li>
            <li><a href="index.html#people"><i class="fas fa-users"></i> People</a></li>
            <li><a href="index.html#updates"><i class="fas fa-bullhorn"></i> Updates</a></li>
            <li><a href="events.html"><i class="fas fa-calendar-alt"></i> Events</a></li>
        </ul>
    </nav>

    <!-- Section 1 -->
    <!-- Introduction Section -->
<section class="intro-section">
    <div class="container">
        <h2>Our Goal</h2>
        <!-- First Paragraph: Full Width -->
        <p class="full-width">
            Audio General Intelligence—the capacity of AI agents to deeply understand and reason about all types of auditory input, including speech, environmental sounds, and music—is crucial for enabling AI to interact seamlessly and naturally with our world. Despite this importance, audio intelligence has traditionally lagged behind advancements in vision and language processing. This gap arises from significant challenges, such as limited datasets, the complexity of audio signals, and a shortage of advanced neural architectures and effective training methodologies tailored specifically for audio. Recent breakthroughs in Large Language Models (LLMs) have begun to transform the landscape. By demonstrating unprecedented capabilities in language comprehension and reasoning, LLMs offer promising pathways to not only enhance foundational audio tasks like Automatic Speech Recognition (ASR), cross-modal retrieval, and audio captioning, but also give emergence to new tasks like complex Audio Question Answering. However, achieving genuine Audio General Intelligence—characterized by complex reasoning and understanding comparable to expert human cognition—remains an ambitious goal yet to be fully realized.
        </p>
        <!-- Wrapper for Image and Subsequent Paragraphs -->
        <div class="text-image-wrapper">
            <img src="assets/GAMA_hero.jpeg" alt="GAMA Hero Image" class="intro-image">
            <p>
                At GAMMA Lab, University of Maryland, our mission is to accelerate progress toward Audio General Intelligence through open and accessible innovations. Our flagship models, GAMA, Audio Flamingo 2 and Audio Flamingo 3, embody this vision, featuring specialized architectures, optimized audio encoders, and meticulously curated alignment datasets. These models excel in complex reasoning tasks, audio understanding, and minimizing hallucinations, setting new benchmarks across the field.            
            </p>
            <p>
                Looking ahead, we foresee Audio General Intelligence playing a pivotal role in daily life—supporting conversational question answering, extracting structured information from audio, and answering knowledge-intensive queries across diverse auditory contexts. To realize this vision, we are extending Audio Flamingo models to handle longer-duration audio and integrating multimodal capabilities to interpret visual information alongside auditory inputs, thereby enabling sophisticated reasoning over extensive video content. Equally important is measurable progress; hence, we released MMAU, a comprehensive benchmark assessing LALMs in practical, real-world tasks. Future benchmarks will further challenge models with complex reasoning scenarios over extended and multi-audio contexts.
            </p>
            <p>
                Through open-source models, advanced synthetic data frameworks, and rigorous evaluation benchmarks, GAMMA Lab is committed to driving forward Audio General Intelligence, fostering community engagement, transparency, and collaboration. By maintaining an open ecosystem, we ensure that audio intelligence technologies remain inclusive, impactful, and accessible to researchers and practitioners worldwide.
            </p>
        </div>
    </div>
        <div id="people" class="container custom-spacing">
            <div><h2>People</h2></div>       
        </div>
        <div class="container custom-spacing">    
            <div><h3 class="subtle-header">GAMMA Lab @ Department of Computer Science, UMD</h3>
                
            </div>
        </div>
        <section class="container">
        <div class="advisor-section">
            <div class="advisor-member">
                <a href="https://www.cs.umd.edu/people/dmanocha">
                <img src="people/dinesh.jpg" alt="Advisor's Name" class="advisor-headshot">
                <p class="advisor-name">Prof. Dinesh Manocha</p>
            </a>
            </div>
        </div>
        <div class="team-wrapper">
            <div class="container">
                <h3 class="team-section-title">PhD Students</h3>
                <div class="team-section">
                    <!-- Repeat this block for each person -->
                    <div class="team-member">
                        <a href="https://sakshi113.github.io/">
                            <img src="people/sakshi-sf2.jpeg" alt="Person's Name2 Headshot" class="team-headshot">
                            <p class="team-name">Sakshi</p>
                        </a>
                    </div>
                    <div class="team-member">
                        <a href="https://sreyan88.github.io/research/">
                            <img src="people/sreyan-2.jpg" alt="Person's Name2 Headshot" class="team-headshot">
                            <p class="team-name">Sreyan Ghosh</p>
                        </a>
                    </div>
                    <div class="team-member">
                        <a href="https://sonalkum.github.io">
                            <img src="people/sonal.png" alt="Person's Name2 Headshot" class="team-headshot">
                            <p class="team-name">Sonal Kumar</p>
                        </a>
                    </div>
                    <div class="team-member">
                        <a href="https://cs20s030.github.io/">
                            <img src="people/ashish.jpeg" alt="Person's Name Headshot" class="team-headshot">
                            <p class="team-name">Ashish Seth</p>
                        </a>
                    </div>   
                </div>
                <h3 class="team-section-title">Masters Students</h3>
                <div class="team-section">
                    <!-- Repeat this block for each person -->
                    <div class="team-member">
                        <a href="https://nishitanand.github.io/">
                            <img src="people/nishit.jpg" alt="Person's Name2 Headshot" class="team-headshot">
                            <p class="team-name">Nishit Anand</p>
                        </a>
                    </div>
                    
                    <div class="team-member">
                        <a href="https://ramaneswaran.github.io/">
                            <img src="people/raman.jpg" alt="Person's Name2 Headshot" class="team-headshot">
                            <p class="team-name">Ramaneswaran S.</p>
                        </a>
                    </div>
                    <div class="team-member">
                        <a href="https://in.linkedin.com/in/apoorva-ak01/">
                            <img src="people/apoorva.jpg" alt="Person's Name2 Headshot" class="team-headshot">
                            <p class="team-name">Apoorva Anand Kulkarni</p>
                        </a>
                    </div>
                    <div class="team-member">
                        <a href="/">
                            <img src="people/kaosheik.jpg" alt="Person's Name2 Headshot" class="team-headshot">
                            <p class="team-name">Kaousheik Jayakumar</p>
                        </a>
                    </div>
                    <div class="team-member">
                        <a href="https://www.linkedin.com/in/vaibhavi-lokegaonkar/">
                            <img src="people/vaibhavi.jpg" alt="Person's Name2 Headshot" class="team-headshot">
                            <p class="team-name">Vaibhavi Lokegaonkar</p>
                        </a>
                    </div>
                    <div class="team-member">
                        <a href="https://www.linkedin.com/in/aryan-bhosale-345497226/">
                            <img src="people/aryan.jpeg" alt="Person's Name2 Headshot" class="team-headshot">
                            <p class="team-name">Aryan Vijay Bhosale</p>
                        </a>
                    </div>

                <h3 class="team-section-title">Alumni</h3>
                <div class="team-section">
                    <div class="team-member">
                        <a href="https://utkarsh4430.github.io/">
                            <img src="people/utkarsh.jpeg" alt="Person's Name2 Headshot" class="team-headshot">
                            <p class="team-name">
                                Utkarsh Tyagi 
                                <span class="now-role">(Now: Research Engineer @ Scale AI)</span>
                            </p>
                        </a>
                    </div>
                    <div class="team-member">
                        <a href="https://www.linkedin.com/in/ckevuru/">
                            <img src="people/chandra.jpeg" alt="Person's Name2 Headshot" class="team-headshot">
                            <p class="team-name">
                                Chandra Kiran Reddy Evuru 
                                <span class="now-role">(Now: Senior Software Engineer @ ServiceNow)</span>
                            </p>
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </section>
</section>

    <!-- Announcement Section -->
    <section class="updates-section" id="updates">
        <div class="container">
            <h2>Updates!</h2>
            <div class="updates-content">
                <p><strong>Sep 2025:</strong> <a href="https://arxiv.org/abs/2507.08128">Audio Flamingo 3</a> accepted to NeurIPS as a spotlight presentation!</p>
                <p><strong>Sep 2025:</strong> Released <a href="https://arxiv.org/abs/2508.13992">MMAU-Pro</a>!</p>
                <p><strong>Sep 2025:</strong> <a href="https://arxiv.org/abs/2507.10859">MultiVox</a>  and <a href="https://arxiv.org/abs/2508.12687">EGOILLUSION</a> accepted to EMNLP 2025 as oral presentations!</p>
                <p><strong>Jul 2025:</strong> Released <a href="https://arxiv.org/abs/2507.08128">Audio Flamingo 3</a>!</p>
                <p><strong>Jan 2025:</strong> 1 paper accepted to ICML 2025!</p>
                <p><strong>Jan 2025:</strong> 3 papers accepted to ICLR 2025!</p>
                <p><strong>Jan 2025:</strong> 3 papers accepted to NAACL 2025!</p>
                <p><strong>Jan 2025:</strong> 3 papers have been accepted to ICASSP 2025!</p>
                <p><strong>Sept 2024:</strong> We released <a href="https://sakshi113.github.io/mmau_homepage/">MMAU</a>, the most comprehensive audio understanding and reasoning benchmark yet!</p>
                <p><strong>Sept 2024:</strong> 2 papers accepted to EMNLP 2024 as oral presentations!</p>
            </div>
        </div>
    </section>


    <!-- Repeat the above project section for each project, updating content and links accordingly -->

    <!-- Footer -->
    <footer>
        <p>&copy; 2025 UMD GAMMA Lab</p>
    </footer>

    <!-- Optional JavaScript for Interactive Effects -->
    <script src="script.js"></script>
</body>
</html>
